{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jiGFqUcMZLdQ"
   },
   "source": [
    "# Fruits and Vegetables Image Recognition\n",
    "\n",
    "\n",
    "```\n",
    "# This is formatted as code\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tz3XJrtkZX8K"
   },
   "source": [
    "# Install required packages (no kagglehub needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow numpy matplotlib scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 73065,
     "status": "ok",
     "timestamp": 1764835732845,
     "user": {
      "displayName": "Youssef Moustaid",
      "userId": "15234993318816449149"
     },
     "user_tz": -60
    },
    "id": "FX4VwWJcZgen",
    "outputId": "244b88f0-f78a-43e8-c76a-c8c71b7ce001"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: ./Fruits-360 dataset/fruits-360_original-size/fruits-360-original-size\n"
     ]
    }
   ],
   "source": [
    "# Using local Fruits-360 dataset\n",
    "DATA_DIR = './Fruits-360 dataset/fruits-360_original-size/fruits-360-original-size'\n",
    "\n",
    "print(\"Path to dataset files:\", DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2uGi2bZufOGD"
   },
   "source": [
    "Info about this dataset :\n",
    "- Train folder contains 100 images per category.\n",
    "- Test : contains 10 images per category.\n",
    "- validation: contiants 10 images per category.\n",
    "\n",
    "The included food items are:\n",
    "\n",
    "Fruits: Banana, Apple, Pear, Grapes, Orange, Kiwi, Watermelon, Pomegranate, Pineapple, Mango\n",
    "Vegetables: Cucumber, Carrot, Capsicum, Onion, Potato, Lemon, Tomato, Radish, Beetroot, Cabbage, Lettuce, Spinach, Soybean, Cauliflower, Bell Pepper, Chilli Pepper, Turnip, Corn, Sweetcorn, Sweet Potato, Paprika, Jalapeño, Ginger, Garlic, Peas, Eggplant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "X5Usu3h8dKRj"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m2vuzuFHcx2V"
   },
   "source": [
    "## ⚙️ Model Training & TFLite Conversion Steps\n",
    "\n",
    "This process assumes you are using Python with TensorFlow/Keras and the MobileNetV2 architecture for Transfer Learning.\n",
    "\n",
    "### **I. Data Preparation**\n",
    "\n",
    "1.  **Organize Dataset:** Ensure your images are split and placed into three distinct directories: `train`, `validation`, and `test`. The subdirectories within each must be named according to their **class** (e.g., `Ripe_Apple`, `Unripe_Apple`).\n",
    "2.  **Define Hyperparameters:** Set the target `IMAGE_SIZE` (e.g., $224 \\times 224$), `BATCH_SIZE`, and number of `EPOCHS`.\n",
    "3.  **Load Data Generators:** Use `ImageDataGenerator` to load images from the directories.\n",
    "    * Apply **rescaling** (e.g., `1./255`) and **Data Augmentation** (e.g., rotation, horizontal flip) to the training set.\n",
    "    * Apply only **rescaling** to the validation set.\n",
    "4.  **Determine Classes:** Automatically retrieve the total number of classification classes (`NUM_CLASSES`) from the data generator.\n",
    "\n",
    "---\n",
    "\n",
    "### **II. Model Training (CNN)**\n",
    "\n",
    "5.  **Load Base Model:** Load the pre-trained **MobileNetV2** model, excluding its top classification layer (`include_top=False`), and using weights pre-trained on ImageNet.\n",
    "6.  **Freeze Base Model:** Set the `base_model.trainable = False` to prevent the pre-trained weights from changing during the initial training phase.\n",
    "7.  **Build Custom Head:** Create a `Sequential` model that stacks:\n",
    "    * The `base_model`.\n",
    "    * A `GlobalAveragePooling2D` layer.\n",
    "    * One or more `Dense` layers (ReLU activation recommended).\n",
    "    * A final `Dense` layer with `NUM_CLASSES` neurons and `softmax` activation.\n",
    "8.  **Compile Model:** Configure the training process using:\n",
    "    * **Optimizer:** `Adam` (with a low learning rate, e.g., $0.0001$).\n",
    "    * **Loss Function:** `categorical_crossentropy`.\n",
    "    * **Metrics:** `['accuracy']`.\n",
    "9.  **Fit Model:** Train the model using the training data, while monitoring performance against the validation data over the specified number of epochs.\n",
    "10. **Save Keras Model:** Save the trained model in the standard Keras format (e.g., `.h5` or `SavedModel`).\n",
    "\n",
    "---\n",
    "\n",
    "### **III. TFLite Conversion & Deployment Prep**\n",
    "\n",
    "11. **Instantiate Converter:** Use `tf.lite.TFLiteConverter.from_keras_model()` with the saved Keras model.\n",
    "12. **Optimize:** Set `converter.optimizations = [tf.lite.Optimize.DEFAULT]` to apply **Post-Training Quantization**. This significantly reduces the model size and improves mobile performance.\n",
    "13. **Convert & Save TFLite:** Execute the conversion and save the result as the optimized TFLite file (e.g., `ripeness_model.tflite`).\n",
    "14. **Save Labels:** Extract the ordered list of class names from the data generator and save them to a plain text file (e.g., `ripeness_labels.txt`).\n",
    "15. **Deploy Assets:** Place both the `.tflite` model file and the `.txt` labels file into the `assets/` directory of your Flutter project.\n",
    "\n",
    "Repeat steps 1 through 15 for the **Fruit Type** and **Fruit Disease** datasets to complete your three-model architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lm1YzhOBc95E"
   },
   "source": [
    "## 1. Data & Model prep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2RXv1vScc6kA"
   },
   "outputs": [],
   "source": [
    "# Hyper params - OPTIMIZED FOR SPEED\n",
    "BATCH_SIZE = 128  # Increased from 64 for faster processing\n",
    "IMAGE_SIZE = (96, 96)  # MobileNetV2 optimal size - faster than 224x224\n",
    "EPOCHS = 12\n",
    "\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, 'Training')\n",
    "VALID_DIR = os.path.join(DATA_DIR, 'Validation')\n",
    "TEST_DIR = os.path.join(DATA_DIR, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1764837649125,
     "user": {
      "displayName": "Youssef Moustaid",
      "userId": "15234993318816449149"
     },
     "user_tz": -60
    },
    "id": "-iHdosbRdGBO",
    "outputId": "fbfd9e38-e711-457f-9785-9afd144aeb28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 39833 images belonging to 112 classes.\n",
      "Found 19921 images belonging to 112 classes.\n",
      "Total classes detected : 112\n"
     ]
    }
   ],
   "source": [
    "# load the data with ImageDataGenerator to load images , resize them, and apply basic data augmentation(rotaiton, flips...) to improve the model's robustness.\n",
    "# Rescale to [0, 1]\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255 ,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "# no augmentation for validaiton\n",
    "valid_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255\n",
    ")\n",
    "# load the training data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size = IMAGE_SIZE,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode= 'categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "validation_generator = valid_datagen.flow_from_directory(\n",
    "    VALID_DIR,\n",
    "    target_size = IMAGE_SIZE,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode= 'categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "# the number of classes for the final layer\n",
    "NUM_CLASSES = train_generator.num_classes\n",
    "print(f\"Total classes detected : {NUM_CLASSES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g6teDNpJhcNP"
   },
   "source": [
    "![img](https://encrypted-tbn3.gstatic.com/licensed-image?q=tbn:ANd9GcS8ZAQqtM-09H9jSR8hOrkmPZkc9c72vG4q97zfwxLmV5101IvOKMpveIKsUGEGooWe-VT6HqSqqps5EPS0vxdXeJ5tckxYrQwiIAtTxLSFUG_rcwE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2969,
     "status": "ok",
     "timestamp": 1764838190102,
     "user": {
      "displayName": "Youssef Moustaid",
      "userId": "15234993318816449149"
     },
     "user_tz": -60
    },
    "id": "VdMrmOFPhEwY",
    "outputId": "eca81243-d827-4bbb-8f3e-b58a82f5996d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_138717/3072170236.py:3: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = tf.keras.applications.MobileNetV2(\n"
     ]
    }
   ],
   "source": [
    "# Load base model\n",
    "# Load MobileNetV2 pre-trained on ImageNet, without the top classification layer\n",
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape = IMAGE_SIZE + (3,),\n",
    "    include_top = False,\n",
    "    weights = 'imagenet'\n",
    ")\n",
    "# Freeze the base model to prevent weights form being updated during the training\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "executionInfo": {
     "elapsed": 97,
     "status": "ok",
     "timestamp": 1764838389252,
     "user": {
      "displayName": "Youssef Moustaid",
      "userId": "15234993318816449149"
     },
     "user_tz": -60
    },
    "id": "s4WyJidJiN9w",
    "outputId": "971c9048-2826-4900-c320-399cd3815525"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ mobilenetv2_1.00_224            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">163,968</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">14,448</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ mobilenetv2_1.00_224            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m2,257,984\u001b[0m │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m163,968\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m)            │        \u001b[38;5;34m14,448\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,436,400</span> (9.29 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,436,400\u001b[0m (9.29 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">178,416</span> (696.94 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m178,416\u001b[0m (696.94 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> (8.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,257,984\u001b[0m (8.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build the custom classififer Head\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(128, activation = 'relu'),\n",
    "    Dropout(0.2),# regularization to prevent overfitting\n",
    "    Dense(NUM_CLASSES, activation = 'softmax') # final classification layer\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "QOgvXaCLj7I_"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = Adam(learning_rate = 0.0001),\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DfvGF8znkZD-"
   },
   "source": [
    "# 2. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RdCyMhGWkXsK",
    "outputId": "a83fb510-48d3-4f96-f2ec-48de7ad54eb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 612ms/step - accuracy: 0.1501 - loss: 3.8845 - val_accuracy: 0.4276 - val_loss: 2.4465\n",
      "Epoch 2/12\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 530ms/step - accuracy: 0.4153 - loss: 2.2612 - val_accuracy: 0.6629 - val_loss: 1.3944\n",
      "Epoch 3/12\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 527ms/step - accuracy: 0.5512 - loss: 1.6223 - val_accuracy: 0.7538 - val_loss: 0.9955\n",
      "Epoch 4/12\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 529ms/step - accuracy: 0.6295 - loss: 1.2974 - val_accuracy: 0.8112 - val_loss: 0.7754\n",
      "Epoch 5/12\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 594ms/step - accuracy: 0.6797 - loss: 1.0960 - val_accuracy: 0.8382 - val_loss: 0.6560\n",
      "Epoch 6/12\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 524ms/step - accuracy: 0.7161 - loss: 0.9594 - val_accuracy: 0.8621 - val_loss: 0.5581\n",
      "Epoch 7/12\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 616ms/step - accuracy: 0.7406 - loss: 0.8633 - val_accuracy: 0.8782 - val_loss: 0.4932\n",
      "Epoch 8/12\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 570ms/step - accuracy: 0.7619 - loss: 0.7832 - val_accuracy: 0.8806 - val_loss: 0.4560\n",
      "Epoch 9/12\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 567ms/step - accuracy: 0.7833 - loss: 0.7147 - val_accuracy: 0.8936 - val_loss: 0.4058\n",
      "Epoch 10/12\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 565ms/step - accuracy: 0.7966 - loss: 0.6646 - val_accuracy: 0.9016 - val_loss: 0.3713\n",
      "Epoch 11/12\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 594ms/step - accuracy: 0.8138 - loss: 0.6173 - val_accuracy: 0.9051 - val_loss: 0.3563\n",
      "Epoch 12/12\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 567ms/step - accuracy: 0.8249 - loss: 0.5758 - val_accuracy: 0.9172 - val_loss: 0.3166\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs = EPOCHS,\n",
    "    validation_data = validation_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "izmPq7rskwVL"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# save the trained keras model for potential future use\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mmodel\u001b[49m.save(\u001b[33m'\u001b[39m\u001b[33mfruit-classifier.h5\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# save the trained keras model for potential future use\n",
    "model.save('fruit-classifier.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4dhg3hxpk6Go"
   },
   "source": [
    "# 3. Plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0og9BaBEk-tT"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Plot training history\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m acc = \u001b[43mhistory\u001b[49m.history[\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      3\u001b[39m val_acc = history.history[\u001b[33m'\u001b[39m\u001b[33mval_accuracy\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      4\u001b[39m loss = history.history[\u001b[33m'\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot training history\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(EPOCHS)  # Fixed: was NUM_EPOCHS, should be EPOCHS\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T4YK3UhwlFFk"
   },
   "source": [
    "# 4. Convert the Keras model to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "p5p0YH6ElD3Z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp8n9xk6y5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp8n9xk6y5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmp8n9xk6y5'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 100, 100, 3), dtype=tf.float32, name='keras_tensor_314')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 112), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  140584282331024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282326992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282326608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282330832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282332176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282331600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282331792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282331984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282331408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282333136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282332560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282332944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282333328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282330256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282333904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282333520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282332752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282333712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282330448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282334864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282334288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282334480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282334672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282332368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282335824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282335248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282335440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282335632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282331216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282336784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282336208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282336400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282336592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282334096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282337744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282337168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282337360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282337552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282335056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282338704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282338128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282338320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282338512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282336016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282339664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282339088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282339280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282339472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282336976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282340624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282340048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282340240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282340816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282341200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282339856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282338896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282340432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941934800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282341008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282337936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941934416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941933840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941933648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941934032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941935760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941935184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941935376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941935568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941934608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941936720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941936144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941936336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941936528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941934224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941937680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941937104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941937296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941937488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941934992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941938640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941938064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941938256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941938448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941935952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941939600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941939024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941939216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941939408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941936912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941940560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941939984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941940176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941940368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941937872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941941520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941940944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941941136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941941328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941938832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941942480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941941904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941942096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941942288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941939792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941943440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941942864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941943056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941943248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941940752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941944400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941943824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941944016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941944208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941941712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941945360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941944784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941944976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941945168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941942672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941946320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941945744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941945936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941946128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941943632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941947280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941946704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941946896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941947088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941944592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941948240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941947664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941947856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941948048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941945552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941949200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941948624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941948816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941949392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941949776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941948432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941947472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941949008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942655696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941949584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941946512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942654736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942655120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942655312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942655504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942656656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942656080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942656272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942656464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942654544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942657616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942657040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942657232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942657424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942654928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942658576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942658000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942658192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942658384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942655888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942659536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942658960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942659152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942659344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942656848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942660496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942659920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942660112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942660304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942657808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942661456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942660880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942661072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942661264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942658768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942662416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942661840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942662032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942662224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942659728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942663376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942662800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942662992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942663184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942660688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942664336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942663760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942663952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942664144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942661648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942665296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942664720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942664912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942665104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942662608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942666256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942665680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942665872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942666064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942663568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942667216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942666640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942666832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942667024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942664528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942668176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942667600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942667792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942667984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942665488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942669136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942668560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942668752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942668944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942666448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942670096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942669520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942669712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942670288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942670672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942669328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942668368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942669904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941344976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942670480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582942667408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941344016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941344400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941344592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941344784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941345936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941345360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941345552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941345744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941343824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941346896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941346320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941346512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941346704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140584282330640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941347088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941346128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941347472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941347664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941344208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941348624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941348048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941348240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941348432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941347280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941349584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941349008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941349200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941349392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941345168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941350544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941348816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941350160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941351888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140582941351120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "TFLite model saved to: ripeness_model.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1764948018.982862  138717 tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "W0000 00:00:1764948018.982880  138717 tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2025-12-05 16:20:18.983153: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp8n9xk6y5\n",
      "2025-12-05 16:20:18.991586: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-12-05 16:20:18.991605: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmp8n9xk6y5\n",
      "I0000 00:00:1764948019.061963  138717 mlir_graph_optimization_pass.cc:437] MLIR V1 optimization pass is not enabled\n",
      "2025-12-05 16:20:19.075368: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-12-05 16:20:19.511291: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmp8n9xk6y5\n",
      "2025-12-05 16:20:19.625898: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 642747 microseconds.\n",
      "2025-12-05 16:20:19.767279: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the TFLite converter\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# Apply default optimization (Post-Training Quantization) for smaller size and faster inference\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# Convert the model\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TFLite model file\n",
    "tflite_model_path = 'fruit-classifier.tflite'\n",
    "with open(tflite_model_path, 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"TFLite model saved to: {tflite_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yi65BB2plODB"
   },
   "source": [
    "# 5. Save the Label map\n",
    "since the flutter pap needs a lsit f the class names in the correct order to interpret the model's output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "oxjs7QCLlWQC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label map saved to: ripeness_labels.txt\n",
      "Final Classes: ['Apple 10', 'Apple 11', 'Apple 12', 'Apple 13', 'Apple 14', 'Apple 17', 'Apple 18', 'Apple 19', 'Apple 5', 'Apple 7', 'Apple 8', 'Apple 9', 'Apple Core 1', 'Apple Red Yellow 2', 'Apple worm 1', 'Avocado Black 1', 'Avocado Black 2', 'Avocado Green 1', 'Banana 3', 'Banana 4', 'Beans 1', 'Blackberrie 1', 'Blackberrie 2', 'Blackberrie half rippen 1', 'Blackberrie not rippen 1', 'Cabbage red 1', 'Cactus fruit green 1', 'Cactus fruit red 1', 'Caju seed 1', 'Cherimoya 1', 'Cherry 3', 'Cherry 4', 'Cherry 5', 'Cherry Rainier 2', 'Cherry Rainier 3', 'Cherry Sour 1', 'Cherry Wax Red 2', 'Cherry Wax Red 3', 'Cherry Wax not ripen 1', 'Cherry Wax not ripen 2', 'Cucumber 1', 'Cucumber 10', 'Cucumber 11', 'Cucumber 3', 'Cucumber 4', 'Cucumber 5', 'Cucumber 6', 'Cucumber 7', 'Cucumber 8', 'Cucumber 9', 'Gooseberry 1', 'Grape not ripen 1', 'Nectarine Flat 2', 'Nut 1', 'Nut 2', 'Nut 3', 'Nut 4', 'Nut 5', 'Onion 2', 'Onion Red 2', 'Onion White Peeled 1', 'Peach 3', 'Peach 4', 'Peach 5', 'Peach 6', 'Pear 1', 'Pear 10', 'Pear 11', 'Pear 12', 'Pear 13', 'Pear 3', 'Pear 5', 'Pear 6', 'Pear 7', 'Pear 8', 'Pear 9', 'Pistachio 1', 'Plum 4', 'Quince 2', 'Quince 3', 'Quince 4', 'Tomato 1', 'Tomato 10', 'Tomato 5', 'Tomato 7', 'Tomato 8', 'Tomato 9', 'Tomato Cherry Maroon 1', 'Tomato Cherry Orange 1', 'Tomato Cherry Red 2', 'Tomato Cherry Yellow 1', 'Tomato Maroon 2', 'apple_6', 'apple_braeburn_1', 'apple_crimson_snow_1', 'apple_golden_1', 'apple_golden_2', 'apple_golden_3', 'apple_granny_smith_1', 'apple_hit_1', 'apple_pink_lady_1', 'apple_red_1', 'apple_red_2', 'apple_red_3', 'apple_red_delicios_1', 'apple_red_yellow_1', 'apple_rotten_1', 'cabbage_white_1', 'carrot_1', 'eggplant_long_1', 'zucchini_1', 'zucchini_dark_1']\n"
     ]
    }
   ],
   "source": [
    "# Get class indices and map them to class names\n",
    "labels = sorted(train_generator.class_indices.items(), key=lambda x: x[1])\n",
    "class_names = [name for name, index in labels]\n",
    "\n",
    "# Save class names to a text file\n",
    "labels_file_path = 'fruit-classifier.txt'\n",
    "with open(labels_file_path, 'w') as f:\n",
    "    f.write('\\n'.join(class_names))\n",
    "\n",
    "print(f\"Label map saved to: {labels_file_path}\")\n",
    "print(\"Final Classes:\", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOi8LjN7nXuXBytGCj6V3Cr",
   "provenance": [
    {
     "file_id": "1WNX_R-ac5LanNCzfz4FnVek7qDzKYJCW",
     "timestamp": 1764838721830
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
