{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jiGFqUcMZLdQ"
   },
   "source": [
    "# Fruits and Vegetables Image Recognition\n",
    "\n",
    "\n",
    "```\n",
    "# This is formatted as code\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tz3XJrtkZX8K"
   },
   "source": [
    "# Install required packages (no kagglehub needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow numpy matplotlib scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 73065,
     "status": "ok",
     "timestamp": 1764835732845,
     "user": {
      "displayName": "Youssef Moustaid",
      "userId": "15234993318816449149"
     },
     "user_tz": -60
    },
    "id": "FX4VwWJcZgen",
    "outputId": "244b88f0-f78a-43e8-c76a-c8c71b7ce001"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Using local Fruits-360 dataset\n",
    "DATA_DIR = './Fruits-360 dataset/fruits-360_original-size/fruits-360-original-size'\n",
    "\n",
    "print(\"Path to dataset files:\", DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2uGi2bZufOGD"
   },
   "source": [
    "Info about this dataset :\n",
    "- Train folder contains 100 images per category.\n",
    "- Test : contains 10 images per category.\n",
    "- validation: contiants 10 images per category.\n",
    "\n",
    "The included food items are:\n",
    "\n",
    "Fruits: Banana, Apple, Pear, Grapes, Orange, Kiwi, Watermelon, Pomegranate, Pineapple, Mango\n",
    "Vegetables: Cucumber, Carrot, Capsicum, Onion, Potato, Lemon, Tomato, Radish, Beetroot, Cabbage, Lettuce, Spinach, Soybean, Cauliflower, Bell Pepper, Chilli Pepper, Turnip, Corn, Sweetcorn, Sweet Potato, Paprika, Jalape√±o, Ginger, Garlic, Peas, Eggplant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X5Usu3h8dKRj"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m2vuzuFHcx2V"
   },
   "source": [
    "## ‚öôÔ∏è Model Training & TFLite Conversion Steps\n",
    "\n",
    "This process assumes you are using Python with TensorFlow/Keras and the MobileNetV2 architecture for Transfer Learning.\n",
    "\n",
    "### **I. Data Preparation**\n",
    "\n",
    "1.  **Organize Dataset:** Ensure your images are split and placed into three distinct directories: `train`, `validation`, and `test`. The subdirectories within each must be named according to their **class** (e.g., `Ripe_Apple`, `Unripe_Apple`).\n",
    "2.  **Define Hyperparameters:** Set the target `IMAGE_SIZE` (e.g., $224 \\times 224$), `BATCH_SIZE`, and number of `EPOCHS`.\n",
    "3.  **Load Data Generators:** Use `ImageDataGenerator` to load images from the directories.\n",
    "    * Apply **rescaling** (e.g., `1./255`) and **Data Augmentation** (e.g., rotation, horizontal flip) to the training set.\n",
    "    * Apply only **rescaling** to the validation set.\n",
    "4.  **Determine Classes:** Automatically retrieve the total number of classification classes (`NUM_CLASSES`) from the data generator.\n",
    "\n",
    "---\n",
    "\n",
    "### **II. Model Training (CNN)**\n",
    "\n",
    "5.  **Load Base Model:** Load the pre-trained **MobileNetV2** model, excluding its top classification layer (`include_top=False`), and using weights pre-trained on ImageNet.\n",
    "6.  **Freeze Base Model:** Set the `base_model.trainable = False` to prevent the pre-trained weights from changing during the initial training phase.\n",
    "7.  **Build Custom Head:** Create a `Sequential` model that stacks:\n",
    "    * The `base_model`.\n",
    "    * A `GlobalAveragePooling2D` layer.\n",
    "    * One or more `Dense` layers (ReLU activation recommended).\n",
    "    * A final `Dense` layer with `NUM_CLASSES` neurons and `softmax` activation.\n",
    "8.  **Compile Model:** Configure the training process using:\n",
    "    * **Optimizer:** `Adam` (with a low learning rate, e.g., $0.0001$).\n",
    "    * **Loss Function:** `categorical_crossentropy`.\n",
    "    * **Metrics:** `['accuracy']`.\n",
    "9.  **Fit Model:** Train the model using the training data, while monitoring performance against the validation data over the specified number of epochs.\n",
    "10. **Save Keras Model:** Save the trained model in the standard Keras format (e.g., `.h5` or `SavedModel`).\n",
    "\n",
    "---\n",
    "\n",
    "### **III. TFLite Conversion & Deployment Prep**\n",
    "\n",
    "11. **Instantiate Converter:** Use `tf.lite.TFLiteConverter.from_keras_model()` with the saved Keras model.\n",
    "12. **Optimize:** Set `converter.optimizations = [tf.lite.Optimize.DEFAULT]` to apply **Post-Training Quantization**. This significantly reduces the model size and improves mobile performance.\n",
    "13. **Convert & Save TFLite:** Execute the conversion and save the result as the optimized TFLite file (e.g., `ripeness_model.tflite`).\n",
    "14. **Save Labels:** Extract the ordered list of class names from the data generator and save them to a plain text file (e.g., `ripeness_labels.txt`).\n",
    "15. **Deploy Assets:** Place both the `.tflite` model file and the `.txt` labels file into the `assets/` directory of your Flutter project.\n",
    "\n",
    "Repeat steps 1 through 15 for the **Fruit Type** and **Fruit Disease** datasets to complete your three-model architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lm1YzhOBc95E"
   },
   "source": [
    "## 1. Data & Model prep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2RXv1vScc6kA"
   },
   "outputs": [],
   "source": [
    "# Hyper params\n",
    "BATCH_SIZE = 64\n",
    "IMAGE_SIZE = (180, 180)\n",
    "EPOCHS = 12\n",
    "\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, 'Training')\n",
    "VALID_DIR = os.path.join(DATA_DIR, 'Validation')\n",
    "TEST_DIR = os.path.join(DATA_DIR, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1764837649125,
     "user": {
      "displayName": "Youssef Moustaid",
      "userId": "15234993318816449149"
     },
     "user_tz": -60
    },
    "id": "-iHdosbRdGBO",
    "outputId": "fbfd9e38-e711-457f-9785-9afd144aeb28"
   },
   "outputs": [],
   "source": [
    "# load the data with ImageDataGenerator to load images , resize them, and apply basic data augmentation(rotaiton, flips...) to improve the model's robustness.\n",
    "# Rescale to [0, 1]\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255 ,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "# no augmentation for validaiton\n",
    "valid_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255\n",
    ")\n",
    "# load the training data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size = IMAGE_SIZE,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode= 'categorical'\n",
    ")\n",
    "validation_generator = valid_datagen.flow_from_directory(\n",
    "    VALID_DIR,\n",
    "    target_size = IMAGE_SIZE,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode= 'categorical'\n",
    ")\n",
    "# the number of classes for the final layer\n",
    "NUM_CLASSES = train_generator.num_classes\n",
    "print(f\"Total classes detected : {NUM_CLASSES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g6teDNpJhcNP"
   },
   "source": [
    "![img](https://encrypted-tbn3.gstatic.com/licensed-image?q=tbn:ANd9GcS8ZAQqtM-09H9jSR8hOrkmPZkc9c72vG4q97zfwxLmV5101IvOKMpveIKsUGEGooWe-VT6HqSqqps5EPS0vxdXeJ5tckxYrQwiIAtTxLSFUG_rcwE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2969,
     "status": "ok",
     "timestamp": 1764838190102,
     "user": {
      "displayName": "Youssef Moustaid",
      "userId": "15234993318816449149"
     },
     "user_tz": -60
    },
    "id": "VdMrmOFPhEwY",
    "outputId": "eca81243-d827-4bbb-8f3e-b58a82f5996d"
   },
   "outputs": [],
   "source": [
    "# Load base model\n",
    "# Load MobileNetV2 pre-trained on ImageNet, without the top classification layer\n",
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape = IMAGE_SIZE + (3,),\n",
    "    include_top = False,\n",
    "    weights = 'imagenet'\n",
    ")\n",
    "# Freeze the base model to prevent weights form being updated during the training\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "executionInfo": {
     "elapsed": 97,
     "status": "ok",
     "timestamp": 1764838389252,
     "user": {
      "displayName": "Youssef Moustaid",
      "userId": "15234993318816449149"
     },
     "user_tz": -60
    },
    "id": "s4WyJidJiN9w",
    "outputId": "971c9048-2826-4900-c320-399cd3815525"
   },
   "outputs": [],
   "source": [
    "# Build the custom classififer Head\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(128, activation = 'relu'),\n",
    "    Dropout(0.2),# regularization to prevent overfitting\n",
    "    Dense(NUM_CLASSES, activation = 'softmax') # final classification layer\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QOgvXaCLj7I_"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = Adam(learning_rate = 0.0001),\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DfvGF8znkZD-"
   },
   "source": [
    "# 2. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RdCyMhGWkXsK",
    "outputId": "a83fb510-48d3-4f96-f2ec-48de7ad54eb7"
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs = EPOCHS,\n",
    "    validation_data = validation_generator, \n",
    "\n",
    "    # üí• CRITICAL SPEED BOOST:\n",
    "    workers=os.cpu_count() # Use all available CPU cores for data loading\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "izmPq7rskwVL"
   },
   "outputs": [],
   "source": [
    "# save the trained keras model for potential future use\n",
    "model.save('ripness_cnn_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4dhg3hxpk6Go"
   },
   "source": [
    "# 3. Plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0og9BaBEk-tT"
   },
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(NUM_EPOCHS)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T4YK3UhwlFFk"
   },
   "source": [
    "# 4. Convert the Keras model to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p5p0YH6ElD3Z"
   },
   "outputs": [],
   "source": [
    "# Initialize the TFLite converter\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# Apply default optimization (Post-Training Quantization) for smaller size and faster inference\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# Convert the model\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TFLite model file\n",
    "tflite_model_path = 'ripeness_model.tflite'\n",
    "with open(tflite_model_path, 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"TFLite model saved to: {tflite_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yi65BB2plODB"
   },
   "source": [
    "# 5. Save the Label map\n",
    "since the flutter pap needs a lsit f the class names in the correct order to interpret the model's output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oxjs7QCLlWQC"
   },
   "outputs": [],
   "source": [
    "# Get class indices and map them to class names\n",
    "labels = sorted(train_generator.class_indices.items(), key=lambda x: x[1])\n",
    "class_names = [name for name, index in labels]\n",
    "\n",
    "# Save class names to a text file\n",
    "labels_file_path = 'ripeness_labels.txt'\n",
    "with open(labels_file_path, 'w') as f:\n",
    "    f.write('\\n'.join(class_names))\n",
    "\n",
    "print(f\"Label map saved to: {labels_file_path}\")\n",
    "print(\"Final Classes:\", class_names)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOi8LjN7nXuXBytGCj6V3Cr",
   "provenance": [
    {
     "file_id": "1WNX_R-ac5LanNCzfz4FnVek7qDzKYJCW",
     "timestamp": 1764838721830
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
